"""
Pipeline Principal - Sistema de ClasificaciÃ³n de Postulantes

Este script ejecuta el pipeline completo de Machine Learning:
1. GeneraciÃ³n de datos sintÃ©ticos
2. Preprocesamiento de datos
3. Entrenamiento del modelo CatBoost
4. EvaluaciÃ³n y visualizaciÃ³n de resultados

Autor: Expertos en Data Science
"""

import sys
import os

# Agregar src al path para imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.data_generation import generate_candidate_data
from src.preprocessing import preprocess_pipeline
from src.model import train_model
from src.evaluation import evaluate_model
from src.prediction import generate_predictions
from src.interpretability_alternative import analyze_interpretability_alternative
import pandas as pd


def print_header(text):
    """Imprime un encabezado formateado."""
    print("\n" + "="*70)
    print(f"  {text}")
    print("="*70 + "\n")


def main():
    """Ejecuta el pipeline completo del proyecto."""
    
    print("\n" + "ğŸ¯"*35)
    print("  SISTEMA DE CLASIFICACIÃ“N DE POSTULANTES - MACHINE LEARNING")
    print("  Proyecto de DemostraciÃ³n de Capacidades en Data Science")
    print("ğŸ¯"*35 + "\n")
    
    try:
        # ====================================================================
        # PASO 1: GENERACIÃ“N DE DATOS SINTÃ‰TICOS
        # ====================================================================
        print_header("PASO 1/4: GeneraciÃ³n de Datos SintÃ©ticos")
        
        df = generate_candidate_data(
            n_samples=1500,
            output_path='data/raw/candidates.csv'
        )
        
        print("\nâœ… Datos generados exitosamente\n")
        
        # ====================================================================
        # PASO 2: PREPROCESAMIENTO DE DATOS
        # ====================================================================
        print_header("PASO 2/4: Preprocesamiento de Datos")
        
        # Cargar datos antes de preprocesar para obtener nombres
        df_full_data = pd.read_csv('data/raw/candidates.csv')
        
        X_train, X_test, y_train, y_test, preprocessor = preprocess_pipeline(
            data_path='data/raw/candidates.csv'
        )
        
        print("âœ… Preprocesamiento completado exitosamente\n")
        
        # ====================================================================
        # PASO 3: ENTRENAMIENTO DEL MODELO
        # ====================================================================
        print_header("PASO 3/4: Entrenamiento del Modelo CatBoost")
        
        classifier = train_model(
            X_train, y_train,
            X_test, y_test,
            preprocessor.get_categorical_features_indices()
        )
        
        print("âœ… Modelo entrenado y guardado exitosamente\n")
        
        # ====================================================================
        # PASO 4: EVALUACIÃ“N DEL MODELO
        # ====================================================================
        print_header("PASO 4/4: EvaluaciÃ³n del Modelo")
        
        evaluator = evaluate_model(
            classifier.model,
            X_test,
            y_test,
            feature_names=preprocessor.feature_names,
            preprocessor=preprocessor
        )
        
        print("âœ… EvaluaciÃ³n completada exitosamente\n")
        
        # ====================================================================
        # PASO 5: GENERACIÃ“N DE SCORES DE PREDICCIÃ“N
        # ====================================================================
        print_header("PASO 5/6: GeneraciÃ³n de Scores de PredicciÃ³n")
        
        # Obtener nombres del conjunto de test
        # Los datos se dividen 80-20, entonces los Ãºltimos 20% son test
        total_rows = len(df_full_data)
        test_size = int(total_rows * 0.2)
        # Usar seed 42 para replicar el split
        from sklearn.model_selection import train_test_split
        train_indices, test_indices = train_test_split(
            range(total_rows), test_size=0.2, random_state=42,
            stratify=df_full_data['Target']
        )
        test_names = df_full_data.iloc[test_indices]['Nombre'].values
        
        # Generar predicciones con scores
        predictor, predictions_df = generate_predictions(
            classifier.model,
            X_test,
            preprocessor=preprocessor,
            candidate_names=test_names,
            output_path='results/candidate_predictions.csv'
        )
        
        print("âœ… Scores de predicciÃ³n generados y exportados exitosamente\n")
        
        # ====================================================================
        # PASO 6: ANÃLISIS DE INTERPRETABILIDAD (SIN SHAP)
        # ====================================================================
        print_header("PASO 6/6: AnÃ¡lisis de Interpretabilidad del Modelo")
        
        try:
            interpreter = analyze_interpretability_alternative(
                classifier.model,
                X_train,
                X_test,
                y_test=y_test,
                feature_names=preprocessor.feature_names
            )
            
            print("âœ… AnÃ¡lisis de interpretabilidad completado exitosamente\n")
        except Exception as e:
            print(f"âš ï¸ Error durante anÃ¡lisis de interpretabilidad: {str(e)}")
            print(f"   Continuando con el resto del pipeline...\n")
        
        # ====================================================================
        # RESUMEN FINAL
        # ====================================================================
        print("\n" + "ğŸ‰"*35)
        print("  PIPELINE COMPLETADO EXITOSAMENTE")
        print("ğŸ‰"*35 + "\n")
        
        print("ğŸ“ Archivos generados:")
        print("   â”œâ”€â”€ data/raw/candidates.csv                          - Dataset sintÃ©tico")
        print("   â”œâ”€â”€ data/processed/preprocessor.pkl                  - Preprocesador guardado")
        print("   â”œâ”€â”€ models/catboost_model.cbm                        - Modelo entrenado")
        print("   â”œâ”€â”€ models/catboost_model_metadata.pkl               - Metadata del modelo")
        print("   â”œâ”€â”€ results/confusion_matrix.png                     - Matriz de confusiÃ³n")
        print("   â”œâ”€â”€ results/roc_curve.png                            - Curva ROC")
        print("   â”œâ”€â”€ results/feature_importance.png                   - Importancia de features")
        print("   â”œâ”€â”€ results/classification_report.txt                - Reporte detallado")
        print("   â”œâ”€â”€ results/candidate_predictions.csv                - ğŸ†• Scores por candidato")
        print("   â”œâ”€â”€ results/interpretability_feature_importance.png  - ğŸ†• ComparaciÃ³n de importancia")
        print("   â”œâ”€â”€ results/interpretability_partial_dependence.png  - ğŸ†• Partial Dependence Plots")
        print("   â”œâ”€â”€ results/interpretability_individual_*.png        - ğŸ†• AnÃ¡lisis individuales")
        print("   â””â”€â”€ results/interpretability_report.txt              - ğŸ†• Reporte de interpretabilidad")
        
        print("\nğŸ’¡ PrÃ³ximos pasos sugeridos:")
        print("   1. Revisar las visualizaciones en la carpeta 'results/'")
        print("   2. Analizar el CSV de scores de predicciÃ³n para cada candidato")
        print("   3. Estudiar los grÃ¡ficos de interpretabilidad para entender decisiones")
        print("   4. Compartir resultados con la clienta")
        print("   5. Ajustar hiperparÃ¡metros si es necesario")
        print("   6. Probar con datos reales cuando estÃ©n disponibles")
        
        print("\n" + "="*70)
        print("  Â¡Proyecto listo para demostraciÃ³n!")
        print("="*70 + "\n")
        
    except Exception as e:
        print(f"\nâŒ Error durante la ejecuciÃ³n del pipeline: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
