"""
M√≥dulo de generaci√≥n de datos sint√©ticos para el clasificador de postulantes.

Este m√≥dulo crea un dataset ficticio con caracter√≠sticas realistas de candidatos
para entrenar el modelo de clasificaci√≥n.
"""

import pandas as pd
import numpy as np
from faker import Faker
import random
import os

# Configurar semilla para reproducibilidad
np.random.seed(42)
random.seed(42)
fake = Faker('es_CL')  # Faker en espa√±ol de Chile


def generate_candidate_data(n_samples=1500, output_path='data/raw/candidates.csv'):
    """
    Genera un dataset sint√©tico de postulantes de trabajo.
    
    Args:
        n_samples (int): N√∫mero de registros a generar
        output_path (str): Ruta donde guardar el archivo CSV
        
    Returns:
        pd.DataFrame: DataFrame con los datos generados
    """
    
    # Listas de valores posibles para variables categ√≥ricas
    titulos = [
        'Ingeniero Civil', 'Ingeniero Comercial', 'Ingeniero Inform√°tico',
        'Licenciado en Ciencias', 'Contador Auditor', 'Psic√≥logo',
        'T√©cnico en Administraci√≥n', 'T√©cnico en Inform√°tica', 'Abogado',
        'Dise√±ador Gr√°fico', 'Periodista', 'Arquitecto', 'M√©dico', 'Enfermero'
    ]
    
    universidades = [
        'Universidad de Chile', 'Pontificia Universidad Cat√≥lica',
        'Universidad de Santiago', 'Universidad T√©cnica Federico Santa Mar√≠a',
        'Universidad de Concepci√≥n', 'Universidad Adolfo Ib√°√±ez',
        'DUOC UC', 'INACAP', 'Universidad Mayor', 'Universidad Andr√©s Bello',
        'Universidad Diego Portales', 'Instituto Profesional AIEP'
    ]
    
    comunas = [
        'Santiago', 'Providencia', 'Las Condes', '√ëu√±oa', 'Maip√∫',
        'La Florida', 'San Miguel', 'Puente Alto', 'Pe√±alol√©n', 'Quilicura',
        'Estaci√≥n Central', 'Recoleta', 'Independencia', 'Vi√±a del Mar',
        'Valpara√≠so', 'Concepci√≥n', 'La Serena', 'Antofagasta'
    ]
    
    data = {
        'Nombre': [],
        'Edad': [],
        'Titulo_Profesional': [],
        'Universidad_Instituto': [],
        'Palabras_Clave': [],
        'Comuna': [],
        'Presencial': [],
        'Magister': [],
        'Target': []
    }
    
    for _ in range(n_samples):
        # Generar caracter√≠sticas
        nombre = fake.name()
        edad = np.random.randint(22, 66)
        titulo = random.choice(titulos)
        universidad = random.choice(universidades)
        palabras_clave = np.random.randint(0, 21)
        comuna = random.choice(comunas)
        presencial = random.choice(['Si', 'No'])
        magister = random.choice(['Si', 'No'])
        
        # L√≥gica para generar el target con correlaciones realistas
        # Crear un score basado en diferentes factores
        score = 0
        
        # Mayor peso a palabras clave (m√°s keywords = mejor candidato)
        score += palabras_clave * 3
        
        # Mag√≠ster suma puntos
        if magister == 'Si':
            score += 15
        
        # Edad √≥ptima entre 25-45
        if 25 <= edad <= 45:
            score += 10
        elif edad < 25:
            score += 5
        else:
            score += 3
        
        # Disponibilidad presencial suma
        if presencial == 'Si':
            score += 8
        
        # Universidades m√°s prestigiosas suman (simplificaci√≥n)
        if universidad in ['Universidad de Chile', 'Pontificia Universidad Cat√≥lica', 
                          'Universidad T√©cnica Federico Santa Mar√≠a']:
            score += 10
        elif universidad in ['DUOC UC', 'INACAP']:
            score += 5
        
        # T√≠tulos m√°s demandados (simplificaci√≥n para este ejemplo)
        if 'Ingeniero' in titulo or 'Inform√°tico' in titulo:
            score += 8
        elif 'T√©cnico' in titulo:
            score += 4
        
        # Convertir score a probabilidad de aceptaci√≥n
        # A√±adir ruido aleatorio para no tener correlaci√≥n perfecta
        ruido = np.random.normal(0, 10)
        score_final = score + ruido
        
        # Threshold para clasificaci√≥n: Si score > 60, m√°s probable ser aceptado
        probabilidad = 1 / (1 + np.exp(-(score_final - 60) / 10))
        target = 'Aceptado' if np.random.random() < probabilidad else 'Rechazado'
        
        # Agregar al dataset
        data['Nombre'].append(nombre)
        data['Edad'].append(edad)
        data['Titulo_Profesional'].append(titulo)
        data['Universidad_Instituto'].append(universidad)
        data['Palabras_Clave'].append(palabras_clave)
        data['Comuna'].append(comuna)
        data['Presencial'].append(presencial)
        data['Magister'].append(magister)
        data['Target'].append(target)
    
    # Crear DataFrame
    df = pd.DataFrame(data)
    
    # Crear directorio si no existe
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # Guardar a CSV
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"‚úÖ Dataset generado exitosamente: {n_samples} registros")
    print(f"üìÅ Guardado en: {output_path}")
    print(f"\nüìä Distribuci√≥n de la variable target:")
    print(df['Target'].value_counts())
    print(f"\nüìà Proporci√≥n:")
    print(df['Target'].value_counts(normalize=True))
    
    return df


if __name__ == "__main__":
    # Generar datos cuando se ejecuta directamente
    df = generate_candidate_data(n_samples=1500)
    print("\nüîç Primeras 5 filas del dataset:")
    print(df.head())
    print(f"\nüìã Informaci√≥n del dataset:")
    print(df.info())
